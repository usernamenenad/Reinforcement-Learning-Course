{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537b5e08-3c7d-4807-9378-50b51f1e5c21",
   "metadata": {},
   "source": [
    "# Maze (Level 1 Assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee914764-a959-4443-945d-f2afab2d4a31",
   "metadata": {},
   "source": [
    "We are faced with a problem of finding an '*escape route*' for an agent to take to get to the terminal state - basically another reinforcement learning problem. For such a problem, an agents' state is **its' position**, or so called **cell**, and based by on what cell is agent currently at, we are going to try to compute an **optimal action** for it to take, and finally *finish the game* or as we're going to call it - end up stepping on a **terminal cell**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee45f7-d8f6-48f8-a8f7-bdf68bde7e1f",
   "metadata": {},
   "source": [
    "A problem we're going to tackle for Level 1 assignment is constructed in such a way that its' core is **deterministic environment** - *for every action, agent has a probability of 1 of ending up in a particular cell, and probability of 0 to end up on some other cell, based on what action it took.* Of course, taking an action is **deterministic** as well, meaning *it does not depend on agents' state* (on what cell is agent standing on). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d380f6-3e80-468d-b10a-716dd3a21237",
   "metadata": {},
   "source": [
    "## For the start, needed utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd03f58-f1eb-4fd3-bf9d-5eb24750bcad",
   "metadata": {},
   "source": [
    "Firstly, we define an interface for cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f85c6b0-8c97-4010-a3a4-7dd9513efa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Position(ABC):\n",
    "    \"\"\"\n",
    "    Interface class for kinds of positions (1D, 2D etc.)\n",
    "    \"\"\"\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def value(self):\n",
    "        pass\n",
    "\n",
    "class Cell(ABC):\n",
    "    \"\"\"\n",
    "    Interface class for all maze cells.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def position(self) -> Position:\n",
    "        pass\n",
    "\n",
    "    @position.setter\n",
    "    @abstractmethod\n",
    "    def position(self, position: Position):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def reward(self) -> float:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def color(self) -> tuple[int, int, int]:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def is_steppable(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def is_terminal(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def has_value(self) -> bool:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fad0ac-de52-421a-adf9-6870051c60a4",
   "metadata": {},
   "source": [
    "Every cell has a few properties - its' position (read below about it), is it steppable and if it is, reward it returns to an agent for stepping on it, as well as if its' terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e6cd51-7e24-488c-ae0b-1c8f8b0b2956",
   "metadata": {},
   "source": [
    "As you might've noticed, we've defined a ***Position*** class, which will represent how positions are interpreted based on what type of maze are we using (it could be board, graph etc., and all of those types require different interpretation of position.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2934ae2-f8b1-48cc-8f7b-4348241d3076",
   "metadata": {},
   "source": [
    "Now's the time for descendant classes of ***Cell*** class. Firstly, we're defining a ***RegularCell*** class, which represents a steppable, non-terminal cell - just an ordinary cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8145cfea-6787-429b-b983-6508ef9e3c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularCell(Cell):\n",
    "    \"\"\"\n",
    "    A regular cell class.\n",
    "\n",
    "    A non-terminal, steppable cell.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def position(self) -> Position:\n",
    "        return self.__position\n",
    "\n",
    "    @position.setter\n",
    "    def position(self, position: Position):\n",
    "        self.__position = position\n",
    "\n",
    "    @property\n",
    "    def reward(self) -> float:\n",
    "        return self.__reward\n",
    "\n",
    "    @property\n",
    "    def color(self) -> tuple[int, int, int]:\n",
    "        return (255, 255, 255) if self.reward == -1 else (255, 0, 0)\n",
    "\n",
    "    def __init__(self, reward: float):\n",
    "        self.__position: Position = None\n",
    "        self.__reward: float = reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d632e8-912a-4768-87c2-017cfd1ca5ab",
   "metadata": {},
   "source": [
    "***TerminalCell*** class - *where it all ends*. Agent finishes the *maze* by stepping onto this type of cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66412c3-ccb9-4907-8a23-20f419f907f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerminalCell(Cell):\n",
    "    \"\"\"\n",
    "    A terminal cell class.\n",
    "\n",
    "    When an agent steps onto it, a game finishes.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def position(self) -> Position:\n",
    "        return self.__position\n",
    "\n",
    "    @position.setter\n",
    "    def position(self, position: Position):\n",
    "        self.__position = position\n",
    "\n",
    "    @property\n",
    "    def reward(self) -> float:\n",
    "        return self.__reward\n",
    "\n",
    "    @property\n",
    "    def color(self) -> tuple[int, int, int]:\n",
    "        return 0, 0, 255\n",
    "\n",
    "    @property\n",
    "    def is_terminal(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def __init__(self, reward: float):\n",
    "        self.__position: Position = None\n",
    "        self.__reward: float = reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c52434-57c2-4d9b-a7c4-58508b892e14",
   "metadata": {},
   "source": [
    "***TeleportCell*** class - special type of cell used for teleporting an agent onto some other steppable cell, ***but not on other teleport cell***. This class is implemented in such a way that inherits all properties of cell it points to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d4d28a-2cf4-4187-9e29-a083953b9b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeleportCell(Cell):\n",
    "    \"\"\"\n",
    "    A teleport cell class.\n",
    "\n",
    "    When stepped onto it, agent can teleport only on\n",
    "    regular or terminal cells, but not on other\n",
    "    teleports nor wall cells.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def position(self) -> Position:\n",
    "        return self.__position\n",
    "\n",
    "    @position.setter\n",
    "    def position(self, position: Position):\n",
    "        self.__position = position\n",
    "\n",
    "    @property\n",
    "    def reward(self) -> float:\n",
    "        return self.__to_teleport_to.reward\n",
    "\n",
    "    @property\n",
    "    def color(self) -> tuple[int, int, int]:\n",
    "        return 0, 255, 0\n",
    "\n",
    "    @property\n",
    "    def to_teleport_to(self) -> Cell:\n",
    "        return self.__to_teleport_to\n",
    "\n",
    "    @to_teleport_to.setter\n",
    "    def to_teleport_to(self, to_teleport_to: Cell):\n",
    "        self.__to_teleport_to = to_teleport_to\n",
    "\n",
    "    @property\n",
    "    def is_steppable(self) -> bool:\n",
    "        return self.to_teleport_to.is_steppable\n",
    "\n",
    "    @property\n",
    "    def is_terminal(self) -> bool:\n",
    "        return self.to_teleport_to.is_terminal\n",
    "\n",
    "    @property\n",
    "    def has_value(self) -> bool:\n",
    "        return self.to_teleport_to.has_value\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__position: Position = None\n",
    "        self.__to_teleport_to: Cell = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ab244-72e1-4717-b157-1f8650bf1b37",
   "metadata": {},
   "source": [
    "***WallCell*** class - represents a wall. It is, of course, not steppable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e718d696-3e88-4996-a905-6044afd54f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WallCell(Cell):\n",
    "    \"\"\"\n",
    "    A wall cell class.\n",
    "\n",
    "    A non steppable, wall cell.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def position(self) -> Position:\n",
    "        return self.__position\n",
    "\n",
    "    @position.setter\n",
    "    def position(self, position: Position):\n",
    "        self.__position = position\n",
    "\n",
    "    @property\n",
    "    def reward(self) -> float:\n",
    "        return self.__reward\n",
    "\n",
    "    @property\n",
    "    def color(self) -> tuple[int, int, int]:\n",
    "        return 128, 128, 128\n",
    "\n",
    "    @property\n",
    "    def is_steppable(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def has_value(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__position: Position = None\n",
    "        self.__reward: float = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b638b-9b0b-4796-81d7-e6d1cbadd249",
   "metadata": {},
   "source": [
    "Lastly, we're defining a CellGenerator, which will be used to generate cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a31449d-1f66-442d-92f5-c904e2e89f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "CellGenerator = Callable[[], Cell]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90d670-449e-4dbe-9212-e5483d845164",
   "metadata": {},
   "source": [
    "Now that we've defined all types of cells (from now on, we're going to call them **states**), it is time to define **actions**. But, for the purpose of *Level 2* and *Level 3 Assignments*, we're firstly going to define something called **directions**, which basically represent a direction for an agent to follow. By defining directions, we're distincting actions from agent movements' directions. For example, if the ***action*** is defined as '*Go RIGHT*', ***direction*** is '*RIGHT*'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1651a-771e-4fed-b92e-ee268b5c5afa",
   "metadata": {},
   "source": [
    "Practical usage of directions will be shown in *Level 2 Assignment*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b5c181-0308-4f84-b233-36ceabf9dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "class Direction(Enum):\n",
    "    RIGHT = auto()\n",
    "    LEFT = auto()\n",
    "    UP = auto()\n",
    "    DOWN = auto()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_all_directions():\n",
    "        return [Direction.RIGHT, Direction.LEFT, Direction.UP, Direction.DOWN]\n",
    "\n",
    "\n",
    "class Action(Enum):\n",
    "    ACTION_A1 = auto()  # On Level 1 assignment, this would collapse to direction RIGHT\n",
    "    ACTION_A2 = auto()  # On Level 1 assignment, this would collapse to direction LEFT\n",
    "    ACTION_A3 = auto()  # On Level 1 assignment, this would collapse to direction UP\n",
    "    ACTION_A4 = auto()  # On Level 1 assignment, this would collapse to direction DOWN\n",
    "\n",
    "    @staticmethod\n",
    "    def get_all_actions():\n",
    "        return [Action.ACTION_A1, Action.ACTION_A2, Action.ACTION_A4, Action.ACTION_A3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f026ce-58c6-4bb8-8fb8-d382d6d369c4",
   "metadata": {},
   "source": [
    "## Environment's 'Base'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb968d-1268-4e86-ba55-ad36eb090baf",
   "metadata": {},
   "source": [
    "It is time for defining so called '**Base**'. Basically, a ***base*** can be interpreted as a representational structure of a particular environment, be it a **board**, a **graph** or some other structure. It is tightly coupled with *actions* and especially *directions*, because it gives a meaningful sense to the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39067c38-1794-42c7-a067-8fb105bf95f0",
   "metadata": {},
   "source": [
    "Like we've said, bases can be of several types - perfect opportunity for making an interface and grouping types of bases together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa42c66-7bfa-4438-96cc-046026d99b0d",
   "metadata": {},
   "source": [
    "***Important disclaimer*** - we're going to interchangeably use the terms ***state***, ***node***, ***position*** and ***cell***, because, even though they're used in several different contexts, basically mean the same thing. Don't get confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b875a9-ae6e-4860-9066-63f37cdaec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class MazeBase(ABC):\n",
    "    \"\"\"\n",
    "    Base class for maze.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def nodes(self) -> Dict[Position, Cell]:\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def connections(self) -> Dict[Position, Dict[Direction, Position]]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def __getitem__(self, **kwargs) -> Cell:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_directions(self, s: Position) -> list[Direction]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b70fd1-5052-472f-87ab-e4f478290534",
   "metadata": {},
   "source": [
    "Here we can observe several properties:\n",
    "- '***Nodes***' *property* describes a group of ***nodes***, which represent a single position, a single cell, a single ***state*** in base structure.\n",
    "- '***Connections***' *property* describes what nodes are connected and how they're connected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d453b-d0cb-4555-9591-5886c8950678",
   "metadata": {},
   "source": [
    "Since for the purpose of *Level 1 Assignment*, we're considering only a 'board' type of base, so we're going to define a representation of position on a board (virtually, it is a $n \\times m$ matrix, so each position can be represented by corresponding indicies $(i, j)$ of corresponding matrix), as well as the board itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fe2a6ba-cff3-4f32-a368-24ca7bd5011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoardPosition(Position):\n",
    "    \"\"\"\n",
    "    Inherited from Position class - models a board square.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def value(self) -> tuple[int, int]:\n",
    "        return self.__value\n",
    "\n",
    "    def __init__(self, value: tuple[int, int]):\n",
    "        self.__value = value\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, tuple):\n",
    "            return self.__value == other\n",
    "        elif isinstance(other, BoardPosition):\n",
    "            return self.__value == other.__value\n",
    "\n",
    "        raise Exception(\n",
    "            f\"Cannot use '==' in context of {other.__class__.__name__}\"\n",
    "        )\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__value)\n",
    "\n",
    "    def __getitem__(self, key: int):\n",
    "        if key in [0, 1]:\n",
    "            return self.__value[key]\n",
    "\n",
    "        raise Exception(\n",
    "            f\"No position {key} in this base!\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3260aa44-4fe8-4c16-b32b-b07a7a6cfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "\n",
    "class MazeBoard(MazeBase):\n",
    "    \"\"\"\n",
    "    Inherited from MazeBase class - models a board.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def nodes(self) -> Dict[Position, Cell]:\n",
    "        return self.__nodes\n",
    "\n",
    "    @property\n",
    "    def connections(self) -> Dict[Position, Dict[Direction, Position]]:\n",
    "        return self.__connections\n",
    "\n",
    "    @property\n",
    "    def rows_no(self) -> int:\n",
    "        return self.__rows_no\n",
    "\n",
    "    @property\n",
    "    def cols_no(self) -> int:\n",
    "        return self.__cols_no\n",
    "\n",
    "    def __init__(self, size: tuple[int, int], specs: list[tuple[float, CellGenerator]]):\n",
    "        width, height = size\n",
    "        weights = [w for w, _ in specs]\n",
    "        generators = [g for _, g in specs]\n",
    "\n",
    "        def random_cell():\n",
    "            return choices(generators, weights, k=1)[0]()\n",
    "\n",
    "        cells = [[random_cell() for _ in range(width)] for _ in range(height)]\n",
    "\n",
    "        self.__rows_no, self.__cols_no, cells = MazeBoard.__validate_cells(cells)\n",
    "\n",
    "        self.__nodes: Dict[Position, Cell] = \\\n",
    "            {\n",
    "                BoardPosition((i, j)): cells[i][j]\n",
    "                for i in range(self.__rows_no)\n",
    "                for j in range(self.cols_no)\n",
    "            }\n",
    "\n",
    "        self.__connections: Dict[Position, Dict[Direction, Position]] = \\\n",
    "            {\n",
    "                node: {}\n",
    "                for node in self.__nodes\n",
    "            }\n",
    "\n",
    "        self.__set_maze()\n",
    "\n",
    "    def __getitem__(self, key: tuple[int, int]) -> Cell:\n",
    "        for node in self.__nodes:\n",
    "            if node == key:\n",
    "                return self.__nodes[node]\n",
    "\n",
    "        raise Exception(\n",
    "            f\"No item {key} in this base!\"\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def __validate_cells(cells: Iterable[Iterable[Cell]]) -> tuple[int, int, list[list[Cell]]]:\n",
    "        \"\"\"\n",
    "        Utility function used to validate the given double-iterable of cells.\n",
    "\n",
    "        If checks are successful, it will return number of board rows and\n",
    "        columns, as well as cells themselves.\n",
    "        \"\"\"\n",
    "        cells = [list(row) for row in cells] if cells else []\n",
    "\n",
    "        if not cells:\n",
    "            raise Exception(\"Number of rows in a board must be at least 1.\")\n",
    "        if not cells[0]:\n",
    "            raise Exception(\"There has to be at least one column.\")\n",
    "\n",
    "        rows_no = len(cells)\n",
    "        cols_no = len(cells[0])\n",
    "\n",
    "        for row in cells:\n",
    "            if not row or len(row) != cols_no:\n",
    "                raise Exception(\n",
    "                    \"Each row in a board must have the same number of columns.\"\n",
    "                )\n",
    "\n",
    "        return rows_no, cols_no, cells\n",
    "\n",
    "    def __right(self, position: tuple[int, int]):\n",
    "        row, col = position\n",
    "        if col != self.__cols_no - 1:\n",
    "            if self[row, col + 1].is_steppable:\n",
    "                return row, col + 1\n",
    "        return row, col\n",
    "\n",
    "    def __left(self, position: tuple[int, int]):\n",
    "        row, col = position\n",
    "        if col != 0:\n",
    "            if self[row, col - 1].is_steppable:\n",
    "                return row, col - 1\n",
    "        return row, col\n",
    "\n",
    "    def __up(self, position: tuple[int, int]):\n",
    "        row, col = position\n",
    "        if row != 0:\n",
    "            if self[row - 1, col].is_steppable:\n",
    "                return row - 1, col\n",
    "        return row, col\n",
    "\n",
    "    def __down(self, position: tuple[int, int]):\n",
    "        row, col = position\n",
    "        if row != self.__rows_no - 1:\n",
    "            if self[row + 1, col].is_steppable:\n",
    "                return row + 1, col\n",
    "        return row, col\n",
    "\n",
    "    def __set_teleport(self):\n",
    "        \"\"\"\n",
    "        Private method for configuring teleport cells - to what\n",
    "        cells will agent teleport when stepped onto teleport cell.\n",
    "        \"\"\"\n",
    "\n",
    "        for node in self.__nodes:\n",
    "            cell = self.__nodes[node]\n",
    "            if isinstance(cell, TeleportCell):\n",
    "                while True:\n",
    "                    tp = choice(list(self.__nodes.keys()))\n",
    "                    tn = self.__nodes[tp]\n",
    "                    if not isinstance(tn, WallCell) and not isinstance(tn, TeleportCell):\n",
    "                        cell.position = tp\n",
    "                        cell.to_teleport_to = tn\n",
    "                        break\n",
    "\n",
    "    def __set_maze(self):\n",
    "        \"\"\"\n",
    "        Private method for creating board -\n",
    "        making board squares (here named nodes).\n",
    "        \"\"\"\n",
    "\n",
    "        self.__set_teleport()\n",
    "\n",
    "        for node in self.__nodes:\n",
    "            self.__nodes[node].position = node\n",
    "            directions = Direction.get_all_directions()\n",
    "\n",
    "            for direction in directions:\n",
    "                if direction == Direction.RIGHT:\n",
    "                    di, dj = self.__right(node.value)\n",
    "                elif direction == Direction.LEFT:\n",
    "                    di, dj = self.__left(node.value)\n",
    "                elif direction == Direction.UP:\n",
    "                    di, dj = self.__up(node.value)\n",
    "                elif direction == Direction.DOWN:\n",
    "                    di, dj = self.__down(node.value)\n",
    "                else:\n",
    "                    raise Exception(\n",
    "                        f\"Board doesn't support {direction.name}!\"\n",
    "                    )\n",
    "                for dnode in self.__nodes:\n",
    "                    if dnode == (di, dj):\n",
    "                        self.__connections[node][direction] = dnode\n",
    "\n",
    "    def compute_direction(self, node: Position, direction: Direction) -> Position:\n",
    "        \"\"\"\n",
    "        Returns a node that is in direction from a given node. If that is a wall cell,\n",
    "        it returns given node.\n",
    "        \"\"\"\n",
    "        return self.__connections[node][direction]\n",
    "\n",
    "    def compute_position(self, position: tuple[int, int]) -> Position:\n",
    "        for node in self.__nodes:\n",
    "            if node == position:\n",
    "                return node\n",
    "\n",
    "        raise Exception(\n",
    "            f\"No position {position} in this base!\"\n",
    "        )\n",
    "\n",
    "    def get_directions(self, node: Position) -> list[Direction]:\n",
    "        return list(self.__connections[node].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799561c-4c06-404a-947a-9c001675af5e",
   "metadata": {},
   "source": [
    "A lot to consider, so we're going to break it all into pieces.\n",
    "- A few added *properties*, such as `rows_no` (number of rows) and `cols_no` (number of columns) a board has.\n",
    "- A board initializer method `__init__` is an initializer for all of the nodes and connections. As we can see, `nodes` is of type `Dict[Position, Cell]`, meaning that it represents a mapping from positions to cells (a *conversion* mechanism). `connections` *property* gives us the overview of internal connections between nodes, therefore it maps a certain position (node) to another position (node) using directions and is the type of `Dict[Position, Dict[Direction, Position]]`.\n",
    "- A few private '*directional*' methods called `__right`, `__left`, `__up` and `__down`, used for computing the corresponding directions. They return the indicies of a cell that is to right, left, up or down of a given cell, and as such only used when constructing a maze.\n",
    "- `__set_teleport` private method is used for randomly selecting one cell from the set of all steppable cell and assigning it to the teleport cell, for all of teleport cells.\n",
    "- `__set_maze` private method 'sets' a maze base, meaning that it will populate `connections` *property* and determine what node is connected to another node in what direction.\n",
    "- `compute_direction` will compute which node is reached after taking given direction from a given node.\n",
    "- `compute_position` is used for converting from tuple of two integers to `Position` class.\n",
    "- `get_directions` will return what directions are possible to follow from the given node. This is particularly importart when dealing with graph bases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb5465-d4d0-406c-a7de-9da4e77e6fa6",
   "metadata": {},
   "source": [
    "## The environment itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2faa24-083e-4006-9fac-59cdcfa7eb42",
   "metadata": {},
   "source": [
    "The time has come to make an ***environment*** itself. We will model the environment as *Markov decision process*, meaning that for a given state and action, it returns the reward signal and the next agent's state. Of course, it is possible to calculate $Q$ values, as well as determining $V$ values from the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c104068-e32c-4619-b8aa-d2cb738dcec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MazeEnvironment:\n",
    "    \"\"\"\n",
    "    Wrapper for a maze board that behaves like an MDP environment.\n",
    "\n",
    "    This is a callable object that behaves like a stochastic MDP\n",
    "    state transition function - given the current state and action,\n",
    "    it returns the following state and reward.\n",
    "\n",
    "    In addition, the environment object is capable of enumerating all\n",
    "    possible states and all possible actions, as well as determining\n",
    "    if the state is terminal.\n",
    "    \"\"\"\n",
    "\n",
    "    @property\n",
    "    def base(self) -> MazeBase:\n",
    "        return self.__base\n",
    "\n",
    "    @property\n",
    "    def states(self) -> list[Position]:\n",
    "        return self.__states\n",
    "\n",
    "    @property\n",
    "    def q_values(self) -> Dict[tuple[Position, Action], float]:\n",
    "        return self.__q_values\n",
    "\n",
    "    @property\n",
    "    def v_values(self) -> Dict[Position, float]:\n",
    "        return self.__v_values\n",
    "\n",
    "    @property\n",
    "    def probabilities(self) -> Dict[tuple[Position, Action], Dict[Direction, float]]:\n",
    "        return self.__probabilities\n",
    "\n",
    "    @property\n",
    "    def gamma(self) -> float:\n",
    "        return self.__gamma\n",
    "\n",
    "    def __init__(self, base: MazeBase, gamma: float = 1):\n",
    "        \"\"\"\n",
    "        Initializer for the environment by specifying the underlying\n",
    "        maze base.\n",
    "        :param base: A base for maze, i.e. *Graph* or *Board*.\n",
    "        :param gamma: Discount factor.\n",
    "        \"\"\"\n",
    "        self.__base = base\n",
    "        self.__states: list[Position] = \\\n",
    "            [\n",
    "                node\n",
    "                for node in self.base.nodes\n",
    "                if self.base[node].is_steppable and not isinstance(self.__base[node], TeleportCell)\n",
    "            ]\n",
    "\n",
    "        # Setting probabilities -\n",
    "        self.__probabilities: Dict[tuple[Position, Action], Dict[Direction, float]] = {}\n",
    "        self.__set_probabilities()\n",
    "\n",
    "        self.__q_values: Dict[tuple[Position, Action], float] = \\\n",
    "            {\n",
    "                (s, a): -10 * random() if not self.is_terminal(s) else 0\n",
    "                for s in self.__states\n",
    "                for a in self.get_actions()\n",
    "            }\n",
    "\n",
    "        self.__v_values: Dict[Position, float] = \\\n",
    "            {\n",
    "                s: self.determine_v(s) for s in self.__states\n",
    "            }\n",
    "\n",
    "        self.__gamma = gamma\n",
    "\n",
    "    def __call__(self, state, action: Action):\n",
    "        \"\"\"\n",
    "        Makes possible for environment class to act as a Markov Decision process -\n",
    "        for a given state and action, it will return new states and rewards.\n",
    "        \"\"\"\n",
    "        snext = []\n",
    "\n",
    "        if not isinstance(state, Position):\n",
    "            state = self.base.compute_position(state)\n",
    "\n",
    "        for direction in self.base.get_directions(state):\n",
    "            new_state = self.compute_direction(state, direction)\n",
    "            new_cell = self.__base[new_state]\n",
    "\n",
    "            if isinstance(new_cell, TeleportCell):\n",
    "                new_state = new_cell.to_teleport_to.position\n",
    "                new_cell = new_cell.to_teleport_to\n",
    "\n",
    "            snext.append(\n",
    "                {\n",
    "                    \"Direction\": direction,\n",
    "                    \"New state\": new_state,\n",
    "                    \"Reward\": new_cell.reward,\n",
    "                    \"Probability\": self.probabilities[(state, action)][direction],\n",
    "                    \"Is terminal\": new_cell.is_terminal,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return snext\n",
    "\n",
    "    # def validate_position(self, row: int, col: int):\n",
    "    #     \"\"\"\n",
    "    #     A utility function that validates a position.\n",
    "    #     \"\"\"\n",
    "    #     if row < 0 or row >= self.base.rows_no:\n",
    "    #         raise Exception(\"Invalid row position\")\n",
    "    #     if col < 0 or col >= self.base.cols_no:\n",
    "    #         raise Exception(\"Invalid column position\")\n",
    "    #     if not self.base[row, col].is_steppable:\n",
    "    #         raise Exception(\"Invalid position: unsteppable cell\")\n",
    "\n",
    "    def __map_da(direction: Direction) -> Action:\n",
    "        if direction == Direction.RIGHT:\n",
    "            return Action.ACTION_A1\n",
    "        elif direction == Direction.LEFT:\n",
    "            return Action.ACTION_A2\n",
    "        elif direction == Direction.UP:\n",
    "            return Action.ACTION_A3\n",
    "        elif direction == Direction.DOWN:\n",
    "            return Action.ACTION_A4\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"No action to map to {direction}!\"\n",
    "            )\n",
    "\n",
    "    def __set_probabilities(self):\n",
    "        \"\"\"\n",
    "        Private method for initializing random probabilities.\n",
    "        Iterating through all states and all possible directions,\n",
    "        then generating probabilities based on number of directions.\n",
    "        \"\"\"\n",
    "        for s in self.__states:\n",
    "            for a in self.get_actions():\n",
    "                self.__probabilities[(s, a)] = {}\n",
    "                for direction in enumerate(self.base.get_directions(s)):\n",
    "                        self.__probabilities[(s, a)][direction] = 1 if a == map_da(direction) else 0\n",
    "\n",
    "    def __update_values(self):\n",
    "        \"\"\"\n",
    "        Private method for updating Q and V values.\n",
    "        \"\"\"\n",
    "        for s in self.states:\n",
    "            if not self.is_terminal(s):\n",
    "                for a in self.get_actions():\n",
    "                    news = self(s, a)\n",
    "                    # q(s, a) = sum(p(s^+, r | s, a)(r + gamma * q(s^+, a^+)))\n",
    "                    self.__q_values[(s, a)] = sum(\n",
    "                        [\n",
    "                            new[\"Probability\"] * (new[\"Reward\"] + self.gamma * self.determine_v(new[\"New state\"]))\n",
    "                            for new in news\n",
    "                        ]\n",
    "                    )\n",
    "                self.__v_values[s] = self.determine_v(s)\n",
    "\n",
    "    def compute_direction(self, state: Position, direction: Direction) -> Position:\n",
    "        \"\"\"\n",
    "        Follow a specific direction in this environment.\n",
    "        If possible, it will use base for computing direction.\n",
    "        \"\"\"\n",
    "\n",
    "        if direction not in self.get_directions():\n",
    "            raise Exception(\n",
    "                f\"Agent cannot move in direction {direction.name} in this environment!\"\n",
    "            )\n",
    "\n",
    "        return self.__base.compute_direction(state, direction)\n",
    "\n",
    "    def compute_values(self, eps: float = 0.01, max_iter: int = 1000):\n",
    "        \"\"\"\n",
    "        Method for converging Q and V values using Bellman's equations.\n",
    "        \"\"\"\n",
    "        for k in range(max_iter):\n",
    "            ov = deepcopy(self.q_values)\n",
    "            self.__update_values()\n",
    "            err = max([abs(self.__q_values[(s, a)] - ov[(s, a)])\n",
    "                       for s, a in self.__q_values])\n",
    "            if err < eps:\n",
    "                return k\n",
    "\n",
    "        return max_iter\n",
    "\n",
    "    def determine_v(self, s: Position):\n",
    "        \"\"\"\n",
    "        Method for determining V values using Q values.\n",
    "        \"\"\"\n",
    "        q = []\n",
    "        for a in self.get_actions():\n",
    "            q.append(\n",
    "                sum(\n",
    "                    [\n",
    "                        self.__probabilities[(s, a)][direction] * self.__q_values[(s, a)]\n",
    "                        for direction in self.base.get_directions(s)\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        # v = max_a(q)\n",
    "        return max(q)\n",
    "\n",
    "    def get_actions(self):\n",
    "        \"\"\"\n",
    "        Returns actions that are possible to take in this\n",
    "        environment.\n",
    "        \"\"\"\n",
    "        return Action.get_all_actions()\n",
    "\n",
    "    def get_directions(self):\n",
    "        \"\"\"\n",
    "        Returns directions that are possible to follow in this\n",
    "        environment.\n",
    "        \"\"\"\n",
    "        return Direction.get_all_directions()\n",
    "\n",
    "    def is_terminal(self, state: Position):\n",
    "        \"\"\"\n",
    "        Returns if the state is terminal.\n",
    "        \"\"\"\n",
    "        return self.__base[state].is_terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf00302-a307-4ffa-be50-196442a1e536",
   "metadata": {},
   "source": [
    "A brief overview of all of the stuff contained in *MazeEnvironment* class:\n",
    "- We can assure that *properties* are self explanatory, besides `properties`, which is explained below.\n",
    "- A first interesting method to look at is `__set_properties` private method, which sets *the probabilities of ending up in some state $s^{+}$ after taking the action $a$ from a certain state $s$*. For the purposes of the *Level 1 Assignment*, we're only considering a ***deterministic MDP***. What is meant by that is, for example, if we take the *Go LEFT* action (which we labeled as *ACTION_A2* above), we are $100\\%$ sure that we'll end up in the left cell - there's no way we end up in the cell right, up or down from where we currently are. A more general case is considered in *Level 2 Assignment*. The mapping between actions and directions is done by `__map_da` private method.\n",
    "- `__call__` method is used for computing *next_state*, *reward*, *direction of next state*, *probability of ending up in that state when taking given action* and *if the next state is terminal*. Basically, we've defined a *MDP* by defining the `__call__` method.\n",
    "- `compute_values` will, as the name says, compute $Q$ values by using the $Q$-*iteration* algorithm. It uses `__update_values` private method to calculate and update $Q$ values iteration by iteration, as well as `determine_v` private method, which will determine new $V$ value after new $Q$ values for state are calculated, for every state. It is important to note that we're calculating ***optimal*** $Q$ and $V$ values, as we can see that, by using `determine_v` method, we're choosing maximum $Q$ out of all $Q$ values when determining $V$, and then using determined $V$ to calculate other needed $Q$ values.\n",
    "- `get_directions` and `get_actions` return a list of directions and actions possible to take and follow in this particular environment, respectfully.\n",
    "- `is_terminal` method will return us whether the given cell is terminal or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64298aa2-4592-43d3-b97a-d2f32a287233",
   "metadata": {},
   "source": [
    "## Defining policies and the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f379c9a-1273-4e31-9173-fb49925a71ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
